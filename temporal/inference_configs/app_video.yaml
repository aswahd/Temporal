sam2_model:
  sam2_checkpoint: checkpoints/sam2.1_hiera_base_plus.pt
  sam2_cfg: configs/sam2.1/sam2.1_hiera_b+.yaml
  apply_postprocessing: false          # fill holes etc.
  use_vos_optimized_video_predictor: false   # fused CUDA kernels

prompt_retriever:
  sampling_strategy: topk              # topk | diverse
  pool_multiplier: 5                   # candidate pool size multiplier (diverse)
  lambda_param: 0.5                    # diversity weight
  context_size: 10
  num_keyframes: 20
  temporal_distance: 4
  confidence_threshold: 0.7
  temporal:
    _target_: temporal.models.utils.embedding_fns.prepare_temporal
    checkpoint_path: null
  dinov2:
    _target_: temporal.models.utils.embedding_fns.prepare_dinov2
    model_key: "dinov2_vitb14"
  clip:
    _target_: temporal.models.utils.embedding_fns.prepare_clip
  embedding_fn: ${prompt_retriever.dinov2}


embedding_fn:
  embedding_fn: ${prompt_retriever.dinov2}


predictor:
  _target_: temporal.models.temporal.build_sam.build_sam2_video_predictor
  config_file:         ${sam2_model.sam2_cfg}
  ckpt_path:           ${sam2_model.sam2_checkpoint}
  apply_postprocessing: ${sam2_model.apply_postprocessing}
  vos_optimized:       ${sam2_model.use_vos_optimized_video_predictor}


segmenter:
  _target_: temporal.app.app_video.Segmenter
  _partial_: true
  predictor:      ${predictor}
  context_size:    ${prompt_retriever.context_size}
  num_keyframes:   ${prompt_retriever.num_keyframes}
  temporal_distance: ${prompt_retriever.temporal_distance}
  confidence_threshold: ${prompt_retriever.confidence_threshold}
  sampling_strategy: ${prompt_retriever.sampling_strategy}
  pool_multiplier: ${prompt_retriever.pool_multiplier}
  lambda_param:    ${prompt_retriever.lambda_param}

dataset:
  _partial_: true
  # _target_: temporal.utils.dataset.MultiMaskDataset
  #ignore_missing_masks: false 
  _target_: temporal.utils.dataset.SingleMaskDataset
  root_dir: /path/to/Train

runtime:
  share: false


